{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy import stats\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
    "from scipy.stats import ttest_ind\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3f5a887f19d9afd",
   "metadata": {},
   "source": "data = pd.read_csv('Employee_Attrition_Data_Set.csv')  #todo:数据集地址",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "20a7e05aafc88822",
   "metadata": {},
   "source": "data.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1dec9725635add55",
   "metadata": {},
   "source": [
    "data.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5bdfede13c30a5aa",
   "metadata": {},
   "source": [
    "data.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3fd6937ca7088936",
   "metadata": {},
   "source": [
    "# Search for all attributes that may be dates\n",
    "date_columns = [col for col in data.columns if data[col].astype(str).str.contains(r'\\b\\d{4}[-/]\\d{2}[-/]\\d{2}\\b', na=False).any()]\n",
    "# Convert date-formatted columns to datetime types\n",
    "for col in date_columns:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "# Print the converted data type\n",
    "#todo:删除上面所有然后写data['A']=pd.to_datetime(data['A']) 或者删除这个todo\n",
    "print(data.dtypes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a5ccc299e564a27a",
   "metadata": {},
   "source": [
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ef3df163f3b7553",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(data.isnull(), cbar=True, cmap='viridis')\n",
    "plt.title('Heat map of missing values')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c69c8925712d58c",
   "metadata": {},
   "source": [
    "# Check the percentage of missing values in each column\n",
    "missing_ratio = data.isnull().mean()\n",
    "# Delete columns with more than 50% missing values\n",
    "cols_to_drop = missing_ratio[missing_ratio > 0.5].index\n",
    "data.drop(columns=cols_to_drop, inplace=True)\n",
    "data.drop(columns=['Employee ID'], inplace=True)  #todo:删除员工ID等无意义的属性 columns=['A','B',....]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0a1cdf0f2332b66",
   "metadata": {},
   "source": [
    "# Fill in missing values\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':  # For string columns\n",
    "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "    elif np.issubdtype(data[column].dtype, np.number):  # For numeric columns\n",
    "        data[column].fillna(data[column].mean(), inplace=True)\n",
    "    elif np.issubdtype(data[column].dtype, np.datetime64):  # For the time column\n",
    "        data[column].fillna(data[column].median(), inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8fbe88a59b7d2ad",
   "metadata": {},
   "source": [
    "num_features = data.select_dtypes(include=[np.number]).columns\n",
    "data[num_features].hist(figsize=(12, 8), bins=15, edgecolor='black')\n",
    "plt.suptitle('Histogram of numerical characteristics')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e19c09cc01e34bd0",
   "metadata": {},
   "source": [
    "num_features = data.select_dtypes(include=[np.number])\n",
    "correlation = num_features.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('correlation heat map')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "431ce2e39a7d5ffd",
   "metadata": {},
   "source": [
    "# Plotting distributions of non-numeric (categorical) attributes\n",
    "object_columns = data.select_dtypes(include=['object']).columns\n",
    "# Create a figure for the plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "# Iterate over the categorical columns and create a subplot for each\n",
    "for i, col in enumerate(object_columns):\n",
    "    # Create a subplot for the current column\n",
    "    plt.subplot(len(object_columns), 1, i + 1)\n",
    "    # Plot the count distribution of the current column\n",
    "    sns.countplot(y=data[col], palette='viridis')\n",
    "    # Set the title and labels for the subplot\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel(col)\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "# Display the plot\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "806f5ccdf4359aa4",
   "metadata": {},
   "source": "sns.boxplot(data['Monthly Income'])  #todo:数值",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.groupby('Department')['Monthly Income'].sum().sort_index().plot()  #todo:标签，数值",
   "id": "4cd480e697397916",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed9d2fb72da4720f",
   "metadata": {},
   "source": "data.groupby('Job Role')['Last Raise Percentage'].mean().sort_index().plot()  #todo:标签，数值",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92163f133f82c64",
   "metadata": {},
   "source": "sns.boxplot(x='Attrition', y='Monthly Income', data=data)  #todo:目标变量，数值",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed545f61c112eccc",
   "metadata": {},
   "source": "plt.hist(data['Distance from Office'], alpha=0.7, color='blue')  #todo:数值",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ebbc17aceec8466",
   "metadata": {},
   "source": [
    "column = 'Monthly Income'  #todo:数值\n",
    "stats.probplot(data[column], dist='norm', plot=plt)\n",
    "print(stats.skew(data[column]))\n",
    "print(stats.kurtosis(data[column], fisher=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b55b9b201e055ae2",
   "metadata": {},
   "source": [
    "column = 'Monthly Income'  #todo:数值\n",
    "stats.probplot(data[column], dist='expon', plot=plt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d70755c370be93f7",
   "metadata": {},
   "source": "data.groupby(['Job Role', 'Department'])['Age'].count().unstack().plot(kind='bar', stacked=True)  #todo:标签，标签，数值",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb4471ba06695897",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 5))\n",
    "sns.boxplot(x='Department', y='Monthly Income', data=data, ax=ax1, palette='tab10')  #todo:标签A，数值B\n",
    "sns.boxplot(x='Department', y='Years at Company', data=data, ax=ax2, palette='tab10')  #todo:标签A，数值C\n",
    "sns.boxplot(x='Department', y='Number of Promotions', data=data, ax=ax3, palette='tab10')  #todo:标签A，数值D"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36c1f518cdc40b4a",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(25, 10))\n",
    "sns.boxplot(x='Job Role', y='Last Raise Percentage', hue='Attrition', data=data, ax=ax1, palette='tab10')  #todo:标签A，数值B，目标变量\n",
    "sns.boxplot(x='Job Role', y='Distance from Office', hue='Attrition', data=data, ax=ax2, palette='tab10')  #todo:标签A，数值C，目标变量\n",
    "sns.boxplot(x='Job Role', y='Job Satisfaction', hue='Attrition', data=data, ax=ax3, palette='tab10')  #todo:标签A，数值D，目标变量"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8fa46c1c48d39cb",
   "metadata": {},
   "source": [
    "left_employees = data[data['Attrition'] == 'Yes']  #todo:目标变量 ，目标变量取值1(在这里Attrition取值不是Yes就是No)\n",
    "stayed_employees = data[data['Attrition'] == 'No']  #todo:目标变量， 目标变量取值2\n",
    "numerical_cols = data.select_dtypes(include='number').columns\n",
    "ttest_results = {}\n",
    "for col in numerical_cols:\n",
    "    t_stat, p_value = ttest_ind(left_employees[col], stayed_employees[col], nan_policy='omit')\n",
    "    ttest_results[col] = {'t_stat': t_stat, 'p_value': p_value}\n",
    "# Convert results to DataFrame for better readability\n",
    "ttest_results_df = pd.DataFrame(ttest_results).T\n",
    "ttest_results_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1977c5f850a907bb",
   "metadata": {},
   "source": [
    "X, y = data.drop(columns=['Attrition']), data['Attrition']  #todo:目标变量\n",
    "y = y.map({'Yes': 1, 'No': 0})  #todo:把标签换成数值\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d618b0af4bfbae22",
   "metadata": {},
   "source": [
    "# Select columns with categorical data\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define a pipeline for transforming categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    # Apply one-hot encoding to handle categorical features\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f64c563b75bcb2f3",
   "metadata": {},
   "source": [
    "# Select columns with numerical data\n",
    "numerical_features = X.select_dtypes(include=['number']).columns\n",
    "# Define a pipeline for transforming numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    # Apply standard scaling to normalize numerical features\n",
    "    ('scaler', StandardScaler())\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6418dc283dfcae20",
   "metadata": {},
   "source": [
    "# Combine numerical and categorical transformers into a single preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    # Apply the numerical transformer to numerical features\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    # Apply the categorical transformer to categorical features\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3151c4d0e453ffcf",
   "metadata": {},
   "source": [
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'classifier__n_neighbors': [5, 7, 9, 15, 35, 45, 55],\n",
    "            'classifier__weights': ['uniform', 'distance'],\n",
    "            'classifier__metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "        }\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {\n",
    "            'classifier__var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_features': ['sqrt', 'log2'],\n",
    "            'classifier__max_depth': [None, 10, 20, 30]\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'Support Vector Machine': {  #todo:支持向量机很费时间，时间不够可以把这个扔掉\n",
    "        'model': SVC(),\n",
    "        'params': {  #todo:也可以删掉一些组合，一共三行参数，只要有一行参数数量大于2就行,[0.1, 1, 10, 100]是四个参数\n",
    "            'classifier__C': [0.1, 1, 10, 100],\n",
    "            'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'classifier__gamma': ['scale', 'auto']\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "240c71761a8574ba",
   "metadata": {},
   "source": [
    "# Initialize a dictionary to store the best models\n",
    "best_models = {}\n",
    "\n",
    "# Define a list of evaluation metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Initialize a dictionary to store the results for each metric\n",
    "results = {metric: [] for metric in metrics}\n",
    "\n",
    "# Initialize a list to store the names of the models\n",
    "model_names = []\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9128f4724477db7",
   "metadata": {},
   "source": [
    "for name, model_params in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model_params['model'])])\n",
    "    param_grid = model_params['params']\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Store the model name\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Calculate and store indicators\n",
    "    results['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    results['precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    results['recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    results['f1'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    print(f'Best parameters for {name}: {grid_search.best_params_}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d6445a039d84279",
   "metadata": {},
   "source": [
    "# Convert the results dictionary to a DataFrame\n",
    "results_data = pd.DataFrame(results, index=model_names)\n",
    "# Transpose the DataFrame so that models are columns and metrics are rows\n",
    "results_data_transposed = results_data.T\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model in results_data_transposed.columns:\n",
    "    plt.plot(results_data_transposed.index, results_data_transposed[model], marker='o', label=model)\n",
    "plt.xlabel('Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61ccad94daff8833",
   "metadata": {},
   "source": [
    "# Create a figure with a 2x2 grid of subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "# Iterate over the axes and the best models\n",
    "for ax, (name, model) in zip(axes, best_models.items()):\n",
    "    # Predict the target values using the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Plot the confusion matrix as a heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    # Set the title and labels for the subplot\n",
    "    ax.set_title(f'Confusion Matrix for {name}')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "# Display the plot\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4522b1b56bf54ac",
   "metadata": {},
   "source": [
    "best_model_index = results['f1'].index(max(results['f1']))\n",
    "best_model_name = model_names[best_model_index]\n",
    "best_model = best_models[best_model_name]\n",
    "# Predicted probability\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "# Calculate ROC curves and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plotting ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Receiver Operating Characteristic (ROC) for {best_model_name}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(f'The best model is: {best_model_name} with an AUC of {roc_auc:.2f}')\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
